{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e0d8ef",
   "metadata": {},
   "source": [
    "# AI Red Teaming Notebook Overview\n",
    "\n",
    "This streamlined notebook guides you through progressively richer AI red teaming evaluations using the Azure AI Evaluation SDK.\n",
    "\n",
    "You will:\n",
    "- Run a fast smoke test with a deterministic safe callback (baseline expectations, near-zero Attack Success Rate).\n",
    "- Target a real Azure OpenAI deployment to observe genuine safety behavior.\n",
    "- Expand coverage across multiple risk categories and layered attack strategies.\n",
    "- Add advanced multi-strategy scans (including composed transformations) to probe layered defenses.\n",
    "- (Optional, end of notebook) Supply your own domain‑specific risky objectives.\n",
    "\n",
    "Artifacts: Each scan writes a JSON scorecard file (label + UTC time). Use these for comparison, regression tracking, or upload into Azure AI Foundry.\n",
    "\n",
    "Execution time scales roughly with: risk_categories × attack_strategies × num_objectives. Start small, expand only after verifying prior steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45803341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed:\n",
      "  - azure-ai-evaluation[redteam]\n",
      "  - azure-identity\n",
      "  - openai\n",
      "  - azure-ai-projects\n",
      "  - python-dotenv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Installation\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "packages = [\n",
    "    \"azure-ai-evaluation[redteam]\",\n",
    "    \"azure-identity\",\n",
    "    \"openai\",\n",
    "    \"azure-ai-projects\",\n",
    "    \"python-dotenv\",\n",
    "]\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"--upgrade\", *packages])\n",
    "print(\"Installed:\")\n",
    "for p in packages:\n",
    "    print(\"  -\", p)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597e5e1",
   "metadata": {},
   "source": [
    "Tracking an issue with latest verion of duckdb switching back to older version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall duckdb -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c29e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install duckdb==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9949f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - imports\n",
    "from typing import Optional, Dict, Any\n",
    "import os\n",
    "\n",
    "# Azure imports\n",
    "from azure.ai.evaluation.red_team import RedTeam, RiskCategory, AttackStrategy\n",
    "\n",
    "# OpenAI import\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c20a58",
   "metadata": {},
   "source": [
    "## Core Concepts: RedTeam, Risk Categories, Attack Strategies & Targets\n",
    "\n",
    "**RedTeam Orchestrator**: Generates attack objectives, transforms prompts via strategies, invokes your target, and scores responses.\n",
    "\n",
    "**Risk Categories (what we probe)**: Violence, Hate/Unfairness, Sexual, SelfHarm. You can supply a subset for faster iteration. Missing categories reduce coverage but cut cost/time.\n",
    "\n",
    "**Attack Strategies (how we probe)**:\n",
    "- Complexity group macros: `EASY`, `MODERATE` (bundles of simpler / moderate transformations)\n",
    "- Individual transformations: Flip, CharSwap, UnicodeConfusable, Leetspeak, Url, Base64, ROT13, etc.\n",
    "- Composition: `AttackStrategy.Compose([Base64, ROT13])` layers transformations to simulate obfuscation chains.\n",
    "\n",
    "**num_objectives**: Count of seed prompts per category (per applied strategy). Linear multiplier on runtime.\n",
    "\n",
    "**Targets (what gets attacked)**:\n",
    "1. Simple synchronous callback (returns fixed text) – deterministic baseline.\n",
    "2. Model configuration dict – RedTeam handles generation calls internally.\n",
    "3. Fully custom (async) application wrapper – replicate real app logic, pre/post-processing.\n",
    "\n",
    "We progress through (1) → (2) → (3+) for clarity.\n",
    "\n",
    "> Tip: Keep early scans lean (≤2 categories, 1 strategy, num_objectives=1) to validate authentication & environment quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Login with a Managed Identity\n",
    "from azure.identity import ManagedIdentityCredential\n",
    "\n",
    "credential = ManagedIdentityCredential()\n",
    "try:\n",
    "    credential.get_token(\"https://management.azure.com/.default\")  # quick probe\n",
    "    print(\"Managed Identity OK.\")\n",
    "except Exception as e:  # noqa: BLE001\n",
    "    raise RuntimeError(\"Managed Identity token acquisition failed.\") from e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06905940",
   "metadata": {},
   "source": [
    "### Authentication Choice: Managed Identity\n",
    "We use `ManagedIdentityCredential` for zero secret management and automatic rotation. The quick token probe confirms the compute environment is wired for Azure resource access.\n",
    "\n",
    "If running outside a managed environment, swap in another credential (e.g., `AzureCliCredential`) without changing later RedTeam logic. All subsequent operations rely only on standard ARM & service tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce743294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 - load .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Attempt a few likely .env locations\n",
    "candidates = [\n",
    "    \"Users/AI-Red-Teaming-Workshop/workshop/files/.env", \n",
    "    \"/files/.env\",\n",
    "    \"./.env\",\n",
    "    os.path.expanduser(\"~/.env\"),\n",
    "]\n",
    "loaded_path = None\n",
    "for p in candidates:\n",
    "    if load_dotenv(dotenv_path=p, override=False):\n",
    "        loaded_path = p\n",
    "        break\n",
    "if not loaded_path:\n",
    "    print(\"WARNING: No .env file loaded from candidates\", candidates)\n",
    "else:\n",
    "    print(f\"Loaded environment variables from: {loaded_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa89a6",
   "metadata": {},
   "source": [
    "### Environment Variables Loaded\n",
    "Required keys (subscription, resource group, project name, OpenAI deployment details, API key & version) enable two things:\n",
    "1. Locating the Azure AI Project for logging / result persistence.\n",
    "2. Invoking your Azure OpenAI deployment during model-based scans.\n",
    "\n",
    "Missing values will be surfaced in the next cell; resolve them before proceeding to model or advanced scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 - Set variables\n",
    "import os\n",
    "\n",
    "_required_keys = [\n",
    "    \"AZURE_SUBSCRIPTION_ID\",\n",
    "    \"AZURE_RESOURCE_GROUP_NAME\",\n",
    "    \"AZURE_PROJECT_NAME\",\n",
    "    \"AZURE_OPENAI_DEPLOYMENT_NAME\",\n",
    "    \"AZURE_OPENAI_ENDPOINT\",\n",
    "    \"AZURE_OPENAI_API_KEY\",\n",
    "    \"AZURE_OPENAI_API_VERSION\",\n",
    "]\n",
    "_env = {k: os.environ.get(k) for k in _required_keys}\n",
    "_missing = [k for k, v in _env.items() if not v]\n",
    "\n",
    "if _missing:\n",
    "    print(\"Missing environment variables:\", _missing)\n",
    "else:\n",
    "    # Construct objects / variables consumed by later cells\n",
    "    azure_ai_project = {\n",
    "        \"subscription_id\": _env[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "        \"resource_group_name\": _env[\"AZURE_RESOURCE_GROUP_NAME\"],\n",
    "        \"project_name\": _env[\"AZURE_PROJECT_NAME\"],\n",
    "        \"credential\": credential,\n",
    "    }\n",
    "    azure_openai_deployment = _env[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "    azure_openai_endpoint = _env[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    azure_openai_api_key = _env[\"AZURE_OPENAI_API_KEY\"]\n",
    "    azure_openai_api_version = _env[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "    print(\"Config loaded.\")\n",
    "    print(f\"Deployment: {azure_openai_deployment}\")\n",
    "    print(f\"Endpoint: {azure_openai_endpoint}\")\n",
    "    print(\"API key prefix:\", azure_openai_api_key[:6] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3add5",
   "metadata": {},
   "source": [
    "### Target Patterns\n",
    "You can point RedTeam at different target styles:\n",
    "- Deterministic callback (fast baseline, isolates framework logic).\n",
    "- Direct model configuration dict (minimal code, invokes deployment directly).\n",
    "- Rich application function (mirrors real system behavior: pre/post-processing, memory, safety layers).\n",
    "\n",
    "We start with the deterministic callback to validate plumbing before spending tokens on real model invocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5208ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Define a simple callback function that always returns a fixed response\n",
    "def financial_advisor_callback(query: str) -> str:  # noqa: ARG001\n",
    "    return \"I'm a financial advisor assistant. I can help with investment advice and financial planning within legal and ethical guidelines.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - Create the `RedTeam` instance with minimal configurations\n",
    "red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    risk_categories=[RiskCategory.Violence, RiskCategory.HateUnfairness],\n",
    "    num_objectives=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b585e",
   "metadata": {},
   "source": [
    "### Minimal Configuration Rationale\n",
    "We start with two categories and `num_objectives=1` to:\n",
    "- Minimize cost & latency.\n",
    "- Confirm authentication, environment variables, and output writing.\n",
    "- Produce a quick baseline artifact for later comparison.\n",
    "\n",
    "Naming pattern: `<Label>-Scan-<UTC hhmmss>` keeps artifacts sortable and unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 - Basic Scan (standardized naming)\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Short timestamp (HHMMSS UTC)\n",
    "scan_ts = datetime.now(timezone.utc).strftime(\"%H%M%S\")\n",
    "scan_label = \"Basic\"\n",
    "scan_name = f\"{scan_label}-Scan-{scan_ts}\"\n",
    "output_path = Path(f\"{scan_label.lower()}_scan-{scan_ts}.json\")\n",
    "\n",
    "# This will test 1 objective prompt for each of Violence and HateUnfairness categories with the Flip strategy\n",
    "basic_scan_result = await red_team.scan(\n",
    "    target=financial_advisor_callback,\n",
    "    scan_name=scan_name,\n",
    "    attack_strategies=[AttackStrategy.Flip],\n",
    "    output_path=str(output_path),\n",
    ")\n",
    "print(f\"Completed {scan_name} -> {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a162cba",
   "metadata": {},
   "source": [
    "### Interpreting the Basic Scan\n",
    "Key metric: **Attack Success Rate (ASR)** = percentage of prompts whose responses are flagged harmful.\n",
    "\n",
    "Because our callback always returns a fixed safe sentence, expected ASR ≈ 0%.\n",
    "\n",
    "Use the emitted JSON to verify structure and plan which additional strategies or categories to add next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Intermediary Scan (standardized naming)\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Lazy client creation (safe on reruns)\n",
    "if '_rt_client' not in globals():\n",
    "    from openai import AzureOpenAI\n",
    "    _rt_client = AzureOpenAI(\n",
    "        api_key=azure_openai_api_key,\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "    )\n",
    "\n",
    "# Accept both invocation styles used internally by RedTeam\n",
    "def model_target(query: str = None, user_prompt: str = None):\n",
    "    prompt = user_prompt if (user_prompt not in (None, \"\")) else query or \"(empty prompt)\"\n",
    "    return _rt_client.chat.completions.create(\n",
    "        model=azure_openai_deployment,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=256,\n",
    "    ).choices[0].message.content or \"\"\n",
    "\n",
    "scan_ts = datetime.now(timezone.utc).strftime('%H%M%S')\n",
    "scan_label = \"Intermediary\"\n",
    "scan_name = f\"{scan_label}-Scan-{scan_ts}\"\n",
    "output_path = Path(f\"{scan_label.lower()}_scan-{scan_ts}.json\")\n",
    "\n",
    "intermediary_scan_result = await red_team.scan(\n",
    "    target=model_target,\n",
    "    scan_name=scan_name,\n",
    "    attack_strategies=[AttackStrategy.Flip],\n",
    "    output_path=str(output_path),\n",
    ")\n",
    "print(f\"Completed {scan_name} -> {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d493e6",
   "metadata": {},
   "source": [
    "### Moving to a Model Target\n",
    "Switching from a deterministic callback to an actual model introduces variability and real guardrail evaluation. Keeping the same single `Flip` strategy isolates model safety behavior from added obfuscation complexity.\n",
    "\n",
    "Next expansions: increase `num_objectives`, add additional strategies (CharSwap, UnicodeConfusable, etc.), or broaden risk categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b80166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Advanced scan - create expanded RedTeam instance\n",
    "advanced_risk_categories = [\n",
    "    RiskCategory.Violence,\n",
    "    RiskCategory.HateUnfairness,\n",
    "    RiskCategory.Sexual,\n",
    "    RiskCategory.SelfHarm,\n",
    "]\n",
    "advanced_red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    risk_categories=advanced_risk_categories,\n",
    "    num_objectives=3,  # increase coverage per category (adjust for cost/time)\n",
    ")\n",
    "print(\"Advanced RedTeam configured with categories:\", [c.name for c in advanced_risk_categories])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cc6d8",
   "metadata": {},
   "source": [
    "### Expanding Coverage\n",
    "We now include all four core risk categories and raise `num_objectives` to increase statistical signal. This increases token/time consumption proportionally.\n",
    "\n",
    "Broader coverage helps surface category-specific weaknesses early (e.g., higher ASR in SelfHarm vs Sexual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Advanced scan + inline stderr ERROR capture (standardized naming)\n",
    "from datetime import datetime, timezone\n",
    "import sys, io, re, contextlib, time, json\n",
    "from pathlib import Path\n",
    "\n",
    "#### Debugger (capture + extract ERROR lines)\n",
    "error_re = re.compile(r'^ERROR:.*', re.IGNORECASE)\n",
    "class _Cap(contextlib.AbstractContextManager):\n",
    "    def __enter__(self):\n",
    "        self._orig = sys.stderr; self.buf = io.StringIO(); sys.stderr = self; return self\n",
    "    def write(self,d): self.buf.write(d); self._orig.write(d)\n",
    "    def flush(self): self._orig.flush()\n",
    "    def __exit__(self,*a): sys.stderr = self._orig\n",
    "#### End Debugger (setup)\n",
    "\n",
    "scan_ts = datetime.now(timezone.utc).strftime('%H%M%S')\n",
    "scan_label = \"Advanced\"\n",
    "scan_name = f\"{scan_label}-Scan-{scan_ts}\"\n",
    "output_path = Path(f\"{scan_label.lower()}_scan-{scan_ts}.json\")\n",
    "\n",
    "with _Cap() as cap:  # debugger active\n",
    "    advanced_scan_result = await advanced_red_team.scan(\n",
    "        target=model_target,\n",
    "        scan_name=scan_name,\n",
    "        attack_strategies=[\n",
    "            AttackStrategy.EASY,\n",
    "            AttackStrategy.MODERATE,\n",
    "            AttackStrategy.Flip,\n",
    "            AttackStrategy.CharSwap,\n",
    "            AttackStrategy.UnicodeConfusable,\n",
    "            AttackStrategy.Leetspeak,\n",
    "            AttackStrategy.Url,\n",
    "            AttackStrategy.Compose([AttackStrategy.Base64, AttackStrategy.ROT13]),\n",
    "        ],\n",
    "        output_path=str(output_path),\n",
    "    )\n",
    "    sys.stderr.flush(); time.sleep(0.2)\n",
    "\n",
    "#### Debugger (ERROR extraction/print)\n",
    "errs = [ln.strip() for ln in cap.buf.getvalue().splitlines() if error_re.match(ln)]\n",
    "print(f\"Completed {scan_name} -> {output_path}\")\n",
    "print(\"No ERROR lines captured.\" if not errs else f\"{len(errs)} ERROR line(s):\\n\" + \"\\n\".join(errs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26883ed",
   "metadata": {},
   "source": [
    "### Advanced Strategies & Layering\n",
    "The advanced scan mixes:\n",
    "- Complexity groups (`EASY`, `MODERATE`) for breadth.\n",
    "- Obfuscations (CharSwap, UnicodeConfusable, Leetspeak, Url) to probe normalization defenses.\n",
    "- Encoding (Base64, ROT13 via composition) to test decoding / content safety layers.\n",
    "\n",
    "Capturing stderr lets you quickly surface any internal SDK errors alongside scan results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcbe2f",
   "metadata": {},
   "source": [
    "## Bring Your Own Objectives: Custom Attack Seed Prompts\n",
    "You can supply your own domain or application-specific risky prompts as objectives instead of (or in addition to) automatically generated ones.\n",
    "\n",
    "Format: a JSON file whose entries include `prompt` text and `risk-type` (one of: `violence`, `sexual`, `hate_unfairness`, `self_harm`). The number of prompts provided becomes the effective `num_objectives` for the scan.\n",
    "\n",
    "Use this when:\n",
    "- You have proprietary misuse scenarios not covered by generic seeds.\n",
    "- You want regression tracking on a fixed, curated risky prompt set.\n",
    "- You need to validate mitigations against previously successful attacks.\n",
    "\n",
    "Below we instantiate a new `RedTeam` with `custom_attack_seed_prompts` pointing to `data/prompts.json`, then run grouped difficulty strategies.\n",
    "\n",
    "> Tip: Keep a version-controlled prompts file so additions are reviewable and diffs tie to shifts in ASR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompts RedTeam instance\n",
    "from pathlib import Path\n",
    "\n",
    "custom_prompts_path = Path(\"data/prompts.json\")\n",
    "assert custom_prompts_path.exists(), f\"Custom prompts file not found: {custom_prompts_path}\"\n",
    "\n",
    "custom_red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    custom_attack_seed_prompts=str(custom_prompts_path),\n",
    ")\n",
    "print(\"Custom RedTeam ready. Prompt count determines num_objectives.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute scan with custom prompts and grouped difficulty strategies\n",
    "custom_result = await custom_red_team.scan(\n",
    "    target=model_target,  # reuse earlier model target callback\n",
    "    scan_name=\"Custom-Prompt-Scan\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,\n",
    "        AttackStrategy.MODERATE,\n",
    "        AttackStrategy.DIFFICULT,\n",
    "    ],\n",
    "    output_path=\"Custom-Prompt-Scan.json\",\n",
    ")\n",
    "print(\"Custom prompt scan complete -> Custom-Prompt-Scan.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
